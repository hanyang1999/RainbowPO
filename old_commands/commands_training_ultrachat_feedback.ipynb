{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Llama-3-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-16 15:50:59,963] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n"
     ]
    }
   ],
   "source": [
    "# Warning: Using transformer version in DPO will lead to errors of loading Llama3\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "transformers.logging.set_verbosity_error()\n",
    "from trl import setup_chat_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6058c6fc3e4872935cdba4dbba1a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\",device_map=\"auto\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\",device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset,DatasetDict\n",
    "#hh_dataset = load_dataset(\"Anthropic/hh-rlhf\")\n",
    "ds = load_dataset(\"<some path>/HuggingFaceH4_ultrafeedback_binarized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train_prefs: Dataset({\n",
       "        features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected'],\n",
       "        num_rows: 61135\n",
       "    })\n",
       "    train_sft: Dataset({\n",
       "        features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected'],\n",
       "        num_rows: 61135\n",
       "    })\n",
       "    test_prefs: Dataset({\n",
       "        features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test_sft: Dataset({\n",
       "        features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    train_gen: Dataset({\n",
       "        features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected'],\n",
       "        num_rows: 61135\n",
       "    })\n",
       "    test_gen: Dataset({\n",
       "        features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rlhf = DatasetDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"train\",\"test\"]:   \n",
    "    ds_rlhf[split] = ds[split+\"_prefs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected'],\n",
       "        num_rows: 61135\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_rlhf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rlhf=ds_rlhf.remove_columns([\"prompt_id\",'messages', 'score_chosen', 'score_rejected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'how can i develop a habit of drawing daily', 'role': 'user'},\n",
       " {'content': \"Developing a daily habit of drawing can be challenging but with consistent practice and a few tips, it can become an enjoyable and rewarding part of your daily routine. Here are some strategies to help you develop the habit of drawing daily:\\n\\n1. Set a specific time: Allocate a specific time of the day to draw. It could be in the morning, afternoon, or evening. Make drawing a part of your daily routine.\\n2. Set a specific duration: Determine the amount of time you want to spend on drawing each day. It can be as little as 10 minutes or as long as an hour. Be consistent with the duration to help build the habit.\\n3. Start small and simple: Don't try to create a masterpiece every day, start with simple and easy-to-do sketches. Focus on improving your skills gradually.\\n4. Use a variety of tools and mediums: Experiment with different tools like pencils, pens, markers, and different mediums like paper, canvas, or digital apps to keep your drawing practice interesting and engaging.\\n5. Take breaks and rest: Taking breaks and resting after some time of drawing can help you avoid burnout and stay motivated.\\n6. Challenge yourself: Set challenges like drawing objects from memory or a specific subject to improve your skills and keep your drawing practice interesting.\\n7. Track your progress: Keep a record of your daily drawing practice and track your progress. This can be a source of motivation and help you see how far you've come.\\n\\nRemember, developing a habit takes time and patience. Stay consistent with your drawing practice, be flexible and open to trying new things, and with time, you'll develop a habit of daily drawing that brings you joy and satisfaction.\",\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_rlhf[\"train\"][\"chosen\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42da4070e0334e798563d3bfb81a5068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/61135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da9b97a509d4992b04b768d7d84b0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_rlhf.save_to_disk(\"<some path>/trl/examples/datasets/UltraFeedback_trl/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Literal\n",
    "\n",
    "LLaMa3_CHAT_template = \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\",\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': \"These instructions apply to section-based themes (Responsive 6.0+, Retina 4.0+, Parallax 3.0+ Turbo 2.0+, Mobilia 5.0+). What theme version am I using?\\nOn your Collections pages & Featured Collections sections, you can easily show the secondary image of a product on hover by enabling one of the theme's built-in settings!\\nYour Collection pages & Featured Collections sections will now display the secondary product image just by hovering over that product image thumbnail.\\nDoes this feature apply to all sections of the theme or just specific ones as listed in the text material?\",\n",
       "   'role': 'user'},\n",
       "  {'content': 'This feature only applies to Collection pages and Featured Collections sections of the section-based themes listed in the text material.',\n",
       "   'role': 'assistant'},\n",
       "  {'content': 'Can you guide me through the process of enabling the secondary image hover feature on my Collection pages and Featured Collections sections?',\n",
       "   'role': 'user'},\n",
       "  {'content': \"Sure, here are the steps to enable the secondary image hover feature on your Collection pages and Featured Collections sections:\\n\\n1. Log in to your Shopify account and go to your Online Store.\\n2. Click on Customize theme for the section-based theme you are using.\\n3. Navigate to the Collection pages or Featured Collections section where you want to enable the secondary image hover feature.\\n4. With the section open, click on the section's setting (gear) icon in the top-left corner.\\n5. In the settings panel that appears, look for an option labeled 'Image display' or 'Image hover'.\\n6. If available, select 'Show secondary image on hover'.\\n7. Save the changes and preview the Collection/Featured Collection page to see the effect.\\n\\nIf you're having trouble finding the setting, the best thing to do is refer to your theme's documentation, since the location and labeling of settings can vary between themes.\",\n",
       "   'role': 'assistant'},\n",
       "  {'content': 'Can you provide me with a link to the documentation for my theme?',\n",
       "   'role': 'user'},\n",
       "  {'content': \"I don't have access to your store's theme information. However, you can usually find the documentation for your theme by going to the shopify theme store, finding your theme and clicking on the 'support' link located in the bottom right corner of the page. Alternatively, you can do a google search for the name of your theme followed by 'documentation' or 'user guide'.\",\n",
       "   'role': 'assistant'},\n",
       "  {'content': 'Can you confirm if this feature also works for the Quick Shop section of my theme?',\n",
       "   'role': 'user'},\n",
       "  {'content': \"The secondary image hover feature may or may not work for your Quick Shop section, depending on the configuration of your theme. Some themes include this feature in the Quick Shop section by default, while others may require additional customization. To check if this feature is available for the Quick Shop section of your theme, follow these steps:\\n\\n1. Go to the Quick Shop section where you would like to enable the feature. 2. Click on the Quick Shop settings icon (gear icon) and look for 'Image display' or 'Image hover'. 3. If available, select 'Show secondary image on hover'. 4. Save the changes. If this option is not available in your Quick Shop section settings, you may need to reach out to your theme developer for assistance with customizing your Quick Shop section to include this feature.\",\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "dataset_path = \"<some path>/trl/examples/datasets/UltraChat_sft_trl\"\n",
    "UltraChat_sft_trl = load_from_disk(dataset_path)\n",
    "UltraChat_sft_trl[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UltraChat_sft_trl[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'how can i develop a habit of drawing daily',\n",
       " 'chosen': [{'content': 'how can i develop a habit of drawing daily',\n",
       "   'role': 'user'},\n",
       "  {'content': \"Developing a daily habit of drawing can be challenging but with consistent practice and a few tips, it can become an enjoyable and rewarding part of your daily routine. Here are some strategies to help you develop the habit of drawing daily:\\n\\n1. Set a specific time: Allocate a specific time of the day to draw. It could be in the morning, afternoon, or evening. Make drawing a part of your daily routine.\\n2. Set a specific duration: Determine the amount of time you want to spend on drawing each day. It can be as little as 10 minutes or as long as an hour. Be consistent with the duration to help build the habit.\\n3. Start small and simple: Don't try to create a masterpiece every day, start with simple and easy-to-do sketches. Focus on improving your skills gradually.\\n4. Use a variety of tools and mediums: Experiment with different tools like pencils, pens, markers, and different mediums like paper, canvas, or digital apps to keep your drawing practice interesting and engaging.\\n5. Take breaks and rest: Taking breaks and resting after some time of drawing can help you avoid burnout and stay motivated.\\n6. Challenge yourself: Set challenges like drawing objects from memory or a specific subject to improve your skills and keep your drawing practice interesting.\\n7. Track your progress: Keep a record of your daily drawing practice and track your progress. This can be a source of motivation and help you see how far you've come.\\n\\nRemember, developing a habit takes time and patience. Stay consistent with your drawing practice, be flexible and open to trying new things, and with time, you'll develop a habit of daily drawing that brings you joy and satisfaction.\",\n",
       "   'role': 'assistant'}],\n",
       " 'rejected': [{'content': 'how can i develop a habit of drawing daily',\n",
       "   'role': 'user'},\n",
       "  {'content': \"As an AI language model, I cannot personally develop habits for you. But, here are some tips for developing a habit of drawing daily:\\n\\n1. Start small: Start with simple drawings or doodles and gradually increase the complexity of your drawings.\\n\\n2. Set a schedule: Set a specific time every day to draw, and try to stick to it as much as possible.\\n\\n3. Make it fun: Don't pressure yourself to create masterpieces every time you draw. Make it a relaxing and enjoyable experience.\\n\\n4. Use resources: There are many drawing tutorials available online. Use resources like YouTube or online drawing courses to help you improve your skills.\\n\\n5. Surround yourself with inspiration: Expose yourself to a variety of art forms, such as paintings, illustrations, and photographs, to inspire and motivate you.\\n\\nRemember, everyone has their own creative style and pace. Just keep practicing and enjoying the process of drawing.\",\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "dataset_path = \"<some path>/trl/examples/datasets/UltraFeedback_trl\"\n",
    "UltraFeedback_trl = load_from_disk(dataset_path)\n",
    "UltraFeedback_trl[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFT: Llama 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FSDP\n",
    "!accelerate launch --config_file=examples/accelerate_configs/FSDP_Llama.yaml --num_processes 8 examples/scripts/sft_fsdp.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraChat_sft_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --attn_implementation 'flash_attention_2' \\\n",
    "    --learning_rate 6e-7 \\\n",
    "    --gradient_accumulation_steps 8 \\\n",
    "    --gradient_checkpointing \\\n",
    "    --logging_steps 10 \\\n",
    "    --output_dir=\"models/Llama3_sft_UltraChat\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --seed 42 \\\n",
    "    --save_steps 5000\\\n",
    "    --warmup_steps 150 #\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FSDP (SimPO hyperparameters)\n",
    "!accelerate launch --config_file=examples/accelerate_configs/FSDP_Llama.yaml --num_processes 8 examples/scripts/sft_fsdp.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraChat_sft_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --attn_implementation 'flash_attention_2' \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --gradient_accumulation_steps 8 \\\n",
    "    --gradient_checkpointing \\\n",
    "    --logging_steps 10 \\\n",
    "    --output_dir=\"models/Llama3_sft-UltraChat_lr_2e-5\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --seed 42 \\\n",
    "    --save_steps 5000\\\n",
    "    --warmup_steps 150 \\\n",
    "    --max_seq_length 2048\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deepspeed Zero3 (SimPO hyperparameters)\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3_sft.yaml --num_processes 8 examples/scripts/sft_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraChat_sft_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B\" \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --attn_implementation 'flash_attention_2' \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --gradient_checkpointing \\\n",
    "    --output_dir=\"models/Llama3_sft-UltraChat_SimPOhyper\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --seed 42 \\\n",
    "    --save_steps 5000\\\n",
    "    --warmup_ratio 0.1 \\\n",
    "    --max_seq_length 2048 \\\n",
    "    --bf16 \\\n",
    "    --logging_steps 10 \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFT: Llama3-Instruct (Is this one needed?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FSDP Llama3-Instruct\n",
    "!accelerate launch --config_file=examples/accelerate_configs/FSDP_Llama.yaml --num_processes 8 examples/scripts/sft_fsdp.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraChat_sft_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --attn_implementation 'flash_attention_2' \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --learning_rate 6e-7 \\\n",
    "    --gradient_accumulation_steps 8 \\\n",
    "    --gradient_checkpointing \\\n",
    "    --logging_steps 10 \\\n",
    "    --output_dir=\"Llama3-Instruct_sft_UltraChat\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --seed 42 \\\n",
    "    --save_steps 5000\\\n",
    "    --warmup_steps 150 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FSDP Llama3-Instruct (SimPO hyperparameters)\n",
    "!accelerate launch --config_file=examples/accelerate_configs/FSDP_Llama.yaml --num_processes 8 examples/scripts/sft_fsdp.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraChat_sft_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --attn_implementation 'flash_attention_2' \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --gradient_accumulation_steps 8 \\\n",
    "    --gradient_checkpointing \\\n",
    "    --logging_steps 10 \\\n",
    "    --output_dir=\"models/Llama3-Instruct_sft_UltraChat_lr_2e-5\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --seed 42 \\\n",
    "    --save_steps 5000\\\n",
    "    --warmup_steps 150 \\\n",
    "    --max_seq_length 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RLHF (Deepspeed Zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLHF on Llama3 SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPO on Llama3 sft \n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/trl/models_sft/Llama3_sft-UltraChat_SimPOhyper/checkpoint-4872\" \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --per_device_eval_batch_size 2 \\\n",
    "    --attn_implementation 'flash_attention_2' \\\n",
    "    --learning_rate 1.0e-6 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3_sft-UltraChat_dpo\" \\\n",
    "    --optim rmsprop \\\n",
    "    --max_length 2048 \\\n",
    "    --max_prompt_length 1800 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --bf16 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPO on Llama3 sft\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/trl/models_sft/Llama3_sft_UltraChat_SimPOhyper/checkpoint-4872\" \\\n",
    "    --loss_type=\"ipo\" \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --per_device_eval_batch_size 2 \\\n",
    "    --attn_implementation 'flash_attention_2' \\\n",
    "    --learning_rate 1.0e-6 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3_sft-UltraChat_ipo\" \\\n",
    "    --optim rmsprop \\\n",
    "    --max_length 2048 \\\n",
    "    --max_prompt_length 1800 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --bf16 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLHF on Llama3-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPO on Llama-3-Instruct\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 4 \\\n",
    "    --attn_implementation 'flash_attention_2' \\\n",
    "    --learning_rate 1.0e-6 \\\n",
    "    --gradient_accumulation_steps 8 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_dpo\" \\\n",
    "    --optim rmsprop \\\n",
    "    --max_length 1024 \\\n",
    "    --max_prompt_length 512 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --bf16 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPO on Llama-3-Instruct (with same setting as SimPO)\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --per_device_eval_batch_size 2 \\\n",
    "    --learning_rate 1.0e-6 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_dpo_2048\" \\\n",
    "    --optim rmsprop \\\n",
    "    --max_length 2048 \\\n",
    "    --max_prompt_length 1800 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --bf16 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
