{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Llama-3-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: Using transformer version in DPO will lead to errors of loading Llama3\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "transformers.logging.set_verbosity_error()\n",
    "from trl import setup_chat_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"  # Replace with the actual model name\n",
    "# save_directory = \"/home/hanyang/Models/\"  # Replace with your desired save directory\n",
    "\n",
    "# Download and save the tokenizer to the specified directory\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Download and save the model to the specified directory\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Literal\n",
    "\n",
    "LLaMa3_CHAT_template = \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\",\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RLHF baselines (Deepspeed Zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLHF on Llama-3-Instruct (IPO $\\beta$=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPO on Llama-3-Instruct\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --learning_rate 1.0e-6 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_ipo_beta_0.001\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 1024 \\\n",
    "    --max_prompt_length 1000 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPO with length normalization\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --learning_rate 1.0e-6 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_ipo_beta_10_normalized\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 1024 \\\n",
    "    --max_prompt_length 1000 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPO with half learning rate\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --learning_rate 5e-7 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_ipo_beta_0.001_lr_0.5\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 1024 \\\n",
    "    --max_prompt_length 1000 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPO with 2048 \n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 1\\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --learning_rate 1e-6 \\\n",
    "    --gradient_accumulation_steps 32 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_ipo_beta_10_LN_hadv_0.2_max_token_2048\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 2048 \\\n",
    "    --max_prompt_length 1800 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLHF on Llama-3-Instruct (ORPO $\\beta$=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORPO on Llama-3-Instruct\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/orpo_zero3.py \\\n",
    "    --dataset=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 2 \\\n",
    "    --learning_rate 1.0e-6 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_orpo_beta_0.1\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 1024 \\\n",
    "    --max_prompt_length 1000 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLHF on Llama-3-Instruct (CPO $\\beta$=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPO on Llama-3-Instruct\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 2 \\\n",
    "    --learning_rate 1.0e-6 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_cpo_beta_0.1\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 1024 \\\n",
    "    --max_prompt_length 1000 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLHF on Llama-3-Instruct (SimPO $\\beta$=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimPO on Llama-3-Instruct\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --learning_rate 1.0e-6 \\\n",
    "    --gradient_accumulation_steps 32 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_simpo_beta_10_hadv_0_max_token_2048_wr_0.1\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 2048 \\\n",
    "    --max_prompt_length 1800 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_ratio 0.1 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimPO on Llama-3-Instruct\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --learning_rate 1.0e-6 \\\n",
    "    --gradient_accumulation_steps 32 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_simpo_beta_10_hadv_0.2_max_token_2048\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 2048 \\\n",
    "    --max_prompt_length 1000 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150\\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mallows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --learning_rate 1.0e-6 \\\n",
    "    --gradient_accumulation_steps 32 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_mallows_dpo_beta_10_normalized_max_token_2048\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 2048 \\\n",
    "    --max_prompt_length 1000 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3_offload.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --learning_rate 1.0e-6 \\\n",
    "    --gradient_accumulation_steps 32 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_mallows_simpo_beta_10_normalized_hadv_0_max_token_2048_wr_0.1\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 2048 \\\n",
    "    --max_prompt_length 1800 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_ratio 0.1 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cauchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --learning_rate 5e-7 \\\n",
    "    --gradient_accumulation_steps 32 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_cauchypo_beta_10_normalized_max_2048\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 2048 \\\n",
    "    --max_prompt_length 1800 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_ratio 0.1 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
