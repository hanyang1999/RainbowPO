{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101765ee374741e18ecede8815a8950a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6602, 0.6758, 0.7930, 0.3730, 0.3555, 0.5859, 0.5703, 0.6992, 0.6367,\n",
      "         0.4453, 0.9414, 0.5195, 0.5430, 0.5430, 0.4023, 0.3809, 0.3809, 0.4238,\n",
      "         0.4473]], device='cuda:0', dtype=torch.bfloat16)\n",
      "{'score': 0.10986328125}\n",
      "tensor([[0.9062, 0.8945, 0.9023, 0.4512, 0.5273, 0.8047, 0.8984, 0.9492, 0.9023,\n",
      "         0.7891, 1.0156, 0.7188, 0.8477, 0.8047, 0.5977, 0.5820, 0.5664, 0.5781,\n",
      "         0.6406]], device='cuda:0', dtype=torch.bfloat16)\n",
      "{'score': 0.1650390625}\n",
      "tensor([[ 0.0806,  0.0825,  0.4531,  0.1367,  0.2100,  0.1709,  0.0339,  0.1455,\n",
      "          0.2188, -0.0013,  0.9727,  0.1523,  0.3203,  0.2432,  0.2471,  0.2656,\n",
      "          0.2158,  0.2871,  0.3164]], device='cuda:0', dtype=torch.bfloat16)\n",
      "{'score': 0.036376953125}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from typing import Dict, List\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "class ArmoRMPipeline:\n",
    "    def __init__(self, model_id, device_map=\"auto\", torch_dtype=torch.bfloat16, truncation=True, trust_remote_code=False, max_length=4096):\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_id,\n",
    "            device_map=device_map,\n",
    "            trust_remote_code=trust_remote_code,\n",
    "            torch_dtype=torch_dtype,\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_id,\n",
    "            use_fast=True,\n",
    "        )\n",
    "        self.truncation = truncation\n",
    "        self.device = self.model.device\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, messages: List[Dict[str, str]]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        messages: OpenAI chat messages to be scored\n",
    "        Note: no batching since due to length differences, the model will have to pad to the max length which is not efficient\n",
    "        Returns: a dictionary with the score between 0 and 1\n",
    "        \"\"\"\n",
    "        input_ids = self.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=self.truncation,\n",
    "            max_length=self.max_length,\n",
    "        ).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_ids)\n",
    "            print(output.rewards)\n",
    "            score = output.score.float().item()\n",
    "        return {\"score\": score}\n",
    "\n",
    "# Create Reward Model Pipeline \n",
    "prompt = 'What are some synonyms for the word \"beautiful\"?'\n",
    "\n",
    "rm_model_path = \"<some fsx path>/Utilities/RLHFlow_ArmoRM-Llama3-8B-v0.1\"\n",
    "\n",
    "# rm = ArmoRMPipeline(\"RLHFlow/ArmoRM-Llama3-8B-v0.1\", trust_remote_code=True)\n",
    "rm = ArmoRMPipeline(rm_model_path, device_map = \"cuda:0\",trust_remote_code=True)\n",
    "\n",
    "# score the messages\n",
    "response1 = 'Nicely, Beautifully, Handsome, Stunning, Wonderful, Gorgeous, Pretty, Stunning, Elegant'\n",
    "\n",
    "score1 = rm([{\"role\": \"user\", \"content\": prompt}, {\"role\": \"assistant\", \"content\": response1}])\n",
    "\n",
    "print(score1)\n",
    "\n",
    "# response 2\n",
    "response2 = '''Certainly! Here are some synonyms for the word \"beautiful\":\n",
    "\n",
    "1. Gorgeous\n",
    "2. Lovely\n",
    "3. Stunning\n",
    "4. Attractive\n",
    "5. Pretty\n",
    "6. Elegant\n",
    "7. Exquisite\n",
    "8. Handsome\n",
    "9. Charming\n",
    "10. Alluring\n",
    "11. Radiant\n",
    "12. Magnificent\n",
    "13. Graceful\n",
    "14. Enchanting\n",
    "15. Dazzling\n",
    "\n",
    "These synonyms can be used in various contexts to convey the idea of beauty.'''\n",
    "score2 = rm([{\"role\": \"user\", \"content\": prompt}, {\"role\": \"assistant\", \"content\": response2}])\n",
    "print(score2)\n",
    "\n",
    "\n",
    "# response 3\n",
    "\n",
    "response3 = 'Sorry i cannot answer this.'\n",
    "score3 = rm([{\"role\": \"user\", \"content\": prompt}, {\"role\": \"assistant\", \"content\": response3}])\n",
    "print(score3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "annotations = pd.read_json(\"<some fsx path>/evaluations/alpaca_eval/results/Llama-3-Instruct-8B-SimPO/weighted_alpaca_eval_gpt4_turbo/annotations.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>output_1</th>\n",
       "      <th>generator_1</th>\n",
       "      <th>dataset</th>\n",
       "      <th>output_2</th>\n",
       "      <th>generator_2</th>\n",
       "      <th>annotator</th>\n",
       "      <th>preference</th>\n",
       "      <th>price_per_example</th>\n",
       "      <th>raw_completion</th>\n",
       "      <th>time_per_example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the names of some famous actors that ...</td>\n",
       "      <td>Several famous actors started their careers on...</td>\n",
       "      <td>gpt4_1106_preview</td>\n",
       "      <td>helpful_base</td>\n",
       "      <td>Many talented actors have transitioned from Br...</td>\n",
       "      <td>Llama-3-Instruct-8B-SimPO</td>\n",
       "      <td>weighted_alpaca_eval_gpt4_turbo</td>\n",
       "      <td>1.251503</td>\n",
       "      <td>0.01373</td>\n",
       "      <td>{'finish_reason': 'length', 'index': 0, 'logpr...</td>\n",
       "      <td>0.157483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How did US states get their names?</td>\n",
       "      <td>The names of U.S. states are derived from a va...</td>\n",
       "      <td>gpt4_1106_preview</td>\n",
       "      <td>helpful_base</td>\n",
       "      <td>The origins of US state names are diverse and ...</td>\n",
       "      <td>Llama-3-Instruct-8B-SimPO</td>\n",
       "      <td>weighted_alpaca_eval_gpt4_turbo</td>\n",
       "      <td>1.000047</td>\n",
       "      <td>0.01506</td>\n",
       "      <td>{'finish_reason': 'length', 'index': 0, 'logpr...</td>\n",
       "      <td>0.157483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi, my sister and her girlfriends want me to p...</td>\n",
       "      <td>Kickball is a fun and simple game that is simi...</td>\n",
       "      <td>gpt4_1106_preview</td>\n",
       "      <td>helpful_base</td>\n",
       "      <td>Don't worry, I'm here to help you navigate kic...</td>\n",
       "      <td>Llama-3-Instruct-8B-SimPO</td>\n",
       "      <td>weighted_alpaca_eval_gpt4_turbo</td>\n",
       "      <td>1.006760</td>\n",
       "      <td>0.01478</td>\n",
       "      <td>{'finish_reason': 'length', 'index': 0, 'logpr...</td>\n",
       "      <td>0.157483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is some cool music from the 1920s?</td>\n",
       "      <td>The 1920s, often referred to as the \"Roaring T...</td>\n",
       "      <td>gpt4_1106_preview</td>\n",
       "      <td>helpful_base</td>\n",
       "      <td>The 1920s! The Jazz Age, the Roaring Twenties!...</td>\n",
       "      <td>Llama-3-Instruct-8B-SimPO</td>\n",
       "      <td>weighted_alpaca_eval_gpt4_turbo</td>\n",
       "      <td>1.007751</td>\n",
       "      <td>0.01329</td>\n",
       "      <td>{'finish_reason': 'length', 'index': 0, 'logpr...</td>\n",
       "      <td>0.157483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I wrap a present neatly?</td>\n",
       "      <td>Wrapping a present neatly can be quite straigh...</td>\n",
       "      <td>gpt4_1106_preview</td>\n",
       "      <td>helpful_base</td>\n",
       "      <td>Wrapping a present neatly requires some basic ...</td>\n",
       "      <td>Llama-3-Instruct-8B-SimPO</td>\n",
       "      <td>weighted_alpaca_eval_gpt4_turbo</td>\n",
       "      <td>1.043222</td>\n",
       "      <td>0.01392</td>\n",
       "      <td>{'finish_reason': 'length', 'index': 0, 'logpr...</td>\n",
       "      <td>0.157483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>Write a script for a YouTube video exploring t...</td>\n",
       "      <td>[Intro]\\n(Upbeat jazz music playing softly in ...</td>\n",
       "      <td>gpt4_1106_preview</td>\n",
       "      <td>vicuna</td>\n",
       "      <td>**Intro**\\n\\n(Upbeat jazz music plays as the h...</td>\n",
       "      <td>Llama-3-Instruct-8B-SimPO</td>\n",
       "      <td>weighted_alpaca_eval_gpt4_turbo</td>\n",
       "      <td>1.307287</td>\n",
       "      <td>0.02215</td>\n",
       "      <td>{'finish_reason': 'length', 'index': 0, 'logpr...</td>\n",
       "      <td>0.142233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>Compose an engaging travel blog post about a r...</td>\n",
       "      <td>Title: Aloha Spirit: A Journey Through the Hea...</td>\n",
       "      <td>gpt4_1106_preview</td>\n",
       "      <td>vicuna</td>\n",
       "      <td>**Island Magic: Unpacking the Rich Culture and...</td>\n",
       "      <td>Llama-3-Instruct-8B-SimPO</td>\n",
       "      <td>weighted_alpaca_eval_gpt4_turbo</td>\n",
       "      <td>1.078495</td>\n",
       "      <td>0.02057</td>\n",
       "      <td>{'finish_reason': 'length', 'index': 0, 'logpr...</td>\n",
       "      <td>0.142233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>Write a captivating movie review for a recentl...</td>\n",
       "      <td>Title: \"Eclipse of Tomorrow\"\\n\\nIn the pantheo...</td>\n",
       "      <td>gpt4_1106_preview</td>\n",
       "      <td>vicuna</td>\n",
       "      <td>**\"Echoes of Eternity\": A Mind-Bending Sci-Fi ...</td>\n",
       "      <td>Llama-3-Instruct-8B-SimPO</td>\n",
       "      <td>weighted_alpaca_eval_gpt4_turbo</td>\n",
       "      <td>1.943814</td>\n",
       "      <td>0.01445</td>\n",
       "      <td>{'finish_reason': 'length', 'index': 0, 'logpr...</td>\n",
       "      <td>0.142233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>Structure a podcast script for an episode disc...</td>\n",
       "      <td># Podcast Episode Script: \"The Streaming Revol...</td>\n",
       "      <td>gpt4_1106_preview</td>\n",
       "      <td>vicuna</td>\n",
       "      <td>**Episode Title:** \"The Streaming Revolution: ...</td>\n",
       "      <td>Llama-3-Instruct-8B-SimPO</td>\n",
       "      <td>weighted_alpaca_eval_gpt4_turbo</td>\n",
       "      <td>1.913258</td>\n",
       "      <td>0.01730</td>\n",
       "      <td>{'finish_reason': 'length', 'index': 0, 'logpr...</td>\n",
       "      <td>0.142233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>Write a symphony concert review, discussing th...</td>\n",
       "      <td>Title: A Night of Resplendent Harmony: The Cap...</td>\n",
       "      <td>gpt4_1106_preview</td>\n",
       "      <td>vicuna</td>\n",
       "      <td>**Maestro's Masterful Direction Elevates Orche...</td>\n",
       "      <td>Llama-3-Instruct-8B-SimPO</td>\n",
       "      <td>weighted_alpaca_eval_gpt4_turbo</td>\n",
       "      <td>1.004434</td>\n",
       "      <td>0.01618</td>\n",
       "      <td>{'finish_reason': 'length', 'index': 0, 'logpr...</td>\n",
       "      <td>0.142233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>805 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           instruction  \\\n",
       "0    What are the names of some famous actors that ...   \n",
       "1                   How did US states get their names?   \n",
       "2    Hi, my sister and her girlfriends want me to p...   \n",
       "3              What is some cool music from the 1920s?   \n",
       "4                      How do I wrap a present neatly?   \n",
       "..                                                 ...   \n",
       "800  Write a script for a YouTube video exploring t...   \n",
       "801  Compose an engaging travel blog post about a r...   \n",
       "802  Write a captivating movie review for a recentl...   \n",
       "803  Structure a podcast script for an episode disc...   \n",
       "804  Write a symphony concert review, discussing th...   \n",
       "\n",
       "                                              output_1        generator_1  \\\n",
       "0    Several famous actors started their careers on...  gpt4_1106_preview   \n",
       "1    The names of U.S. states are derived from a va...  gpt4_1106_preview   \n",
       "2    Kickball is a fun and simple game that is simi...  gpt4_1106_preview   \n",
       "3    The 1920s, often referred to as the \"Roaring T...  gpt4_1106_preview   \n",
       "4    Wrapping a present neatly can be quite straigh...  gpt4_1106_preview   \n",
       "..                                                 ...                ...   \n",
       "800  [Intro]\\n(Upbeat jazz music playing softly in ...  gpt4_1106_preview   \n",
       "801  Title: Aloha Spirit: A Journey Through the Hea...  gpt4_1106_preview   \n",
       "802  Title: \"Eclipse of Tomorrow\"\\n\\nIn the pantheo...  gpt4_1106_preview   \n",
       "803  # Podcast Episode Script: \"The Streaming Revol...  gpt4_1106_preview   \n",
       "804  Title: A Night of Resplendent Harmony: The Cap...  gpt4_1106_preview   \n",
       "\n",
       "          dataset                                           output_2  \\\n",
       "0    helpful_base  Many talented actors have transitioned from Br...   \n",
       "1    helpful_base  The origins of US state names are diverse and ...   \n",
       "2    helpful_base  Don't worry, I'm here to help you navigate kic...   \n",
       "3    helpful_base  The 1920s! The Jazz Age, the Roaring Twenties!...   \n",
       "4    helpful_base  Wrapping a present neatly requires some basic ...   \n",
       "..            ...                                                ...   \n",
       "800        vicuna  **Intro**\\n\\n(Upbeat jazz music plays as the h...   \n",
       "801        vicuna  **Island Magic: Unpacking the Rich Culture and...   \n",
       "802        vicuna  **\"Echoes of Eternity\": A Mind-Bending Sci-Fi ...   \n",
       "803        vicuna  **Episode Title:** \"The Streaming Revolution: ...   \n",
       "804        vicuna  **Maestro's Masterful Direction Elevates Orche...   \n",
       "\n",
       "                   generator_2                        annotator  preference  \\\n",
       "0    Llama-3-Instruct-8B-SimPO  weighted_alpaca_eval_gpt4_turbo    1.251503   \n",
       "1    Llama-3-Instruct-8B-SimPO  weighted_alpaca_eval_gpt4_turbo    1.000047   \n",
       "2    Llama-3-Instruct-8B-SimPO  weighted_alpaca_eval_gpt4_turbo    1.006760   \n",
       "3    Llama-3-Instruct-8B-SimPO  weighted_alpaca_eval_gpt4_turbo    1.007751   \n",
       "4    Llama-3-Instruct-8B-SimPO  weighted_alpaca_eval_gpt4_turbo    1.043222   \n",
       "..                         ...                              ...         ...   \n",
       "800  Llama-3-Instruct-8B-SimPO  weighted_alpaca_eval_gpt4_turbo    1.307287   \n",
       "801  Llama-3-Instruct-8B-SimPO  weighted_alpaca_eval_gpt4_turbo    1.078495   \n",
       "802  Llama-3-Instruct-8B-SimPO  weighted_alpaca_eval_gpt4_turbo    1.943814   \n",
       "803  Llama-3-Instruct-8B-SimPO  weighted_alpaca_eval_gpt4_turbo    1.913258   \n",
       "804  Llama-3-Instruct-8B-SimPO  weighted_alpaca_eval_gpt4_turbo    1.004434   \n",
       "\n",
       "     price_per_example                                     raw_completion  \\\n",
       "0              0.01373  {'finish_reason': 'length', 'index': 0, 'logpr...   \n",
       "1              0.01506  {'finish_reason': 'length', 'index': 0, 'logpr...   \n",
       "2              0.01478  {'finish_reason': 'length', 'index': 0, 'logpr...   \n",
       "3              0.01329  {'finish_reason': 'length', 'index': 0, 'logpr...   \n",
       "4              0.01392  {'finish_reason': 'length', 'index': 0, 'logpr...   \n",
       "..                 ...                                                ...   \n",
       "800            0.02215  {'finish_reason': 'length', 'index': 0, 'logpr...   \n",
       "801            0.02057  {'finish_reason': 'length', 'index': 0, 'logpr...   \n",
       "802            0.01445  {'finish_reason': 'length', 'index': 0, 'logpr...   \n",
       "803            0.01730  {'finish_reason': 'length', 'index': 0, 'logpr...   \n",
       "804            0.01618  {'finish_reason': 'length', 'index': 0, 'logpr...   \n",
       "\n",
       "     time_per_example  \n",
       "0            0.157483  \n",
       "1            0.157483  \n",
       "2            0.157483  \n",
       "3            0.157483  \n",
       "4            0.157483  \n",
       "..                ...  \n",
       "800          0.142233  \n",
       "801          0.142233  \n",
       "802          0.142233  \n",
       "803          0.142233  \n",
       "804          0.142233  \n",
       "\n",
       "[805 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "python decode_test_set.py --model_path \"<some fsx path>/model_zoo/Meta-Llama-3-8B-Instruct\" --model_output_name \"Llama3-Instruct-test\" --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nameoutput_42.json'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'name'+f'output_{seed}.json'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
