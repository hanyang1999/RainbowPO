{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLHF on Llama3-Instruct (DPO $\\beta$=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPO on Llama-3-Instruct\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 2 \\\n",
    "    --learning_rate 1.0e-6 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_dpo_beta_0.1\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 1024 \\\n",
    "    --max_prompt_length 1000 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change learning rate\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 2 \\\n",
    "    --learning_rate 3e-7 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_dpo_beta_0.1_lr_0.3\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 1024 \\\n",
    "    --max_prompt_length 1000 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length normalization\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 2 \\\n",
    "    --learning_rate 1.0e-6 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_dpo_beta_20_hadv_-0.1_normalized\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 1024 \\\n",
    "    --max_prompt_length 1000 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length normalization 2048\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --learning_rate 1.0e-6 \\\n",
    "    --gradient_accumulation_steps 32 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_dpo_beta_10_normalized_max_token_2048\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 2048 \\\n",
    "    --max_prompt_length 1000 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLHF on Llama3-Instruct (DPO $\\beta$=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPO on Llama-3-Instruct\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 2 \\\n",
    "    --learning_rate 1e-6 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_dpo_beta_0.05\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 1024 \\\n",
    "    --max_prompt_length 1000 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change learning rate\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 2 \\\n",
    "    --learning_rate 3e-7 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_dpo_beta_0.05_lr_0.3\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 1024 \\\n",
    "    --max_prompt_length 1000 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length normalization\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 2 \\\n",
    "    --learning_rate 1.0e-6 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_dpo_beta_0.05_normalized\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 1024 \\\n",
    "    --max_prompt_length 1000 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLHF on Llama3-Instruct (DPO $\\beta$=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPO on Llama-3-Instruct\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 2 \\\n",
    "    --learning_rate 1.0e-6 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_dpo_beta_0.01\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 1024 \\\n",
    "    --max_prompt_length 1000 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change learning rate \n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 2 \\\n",
    "    --learning_rate 5e-7 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_dpo_beta_0.01_lr_0.5\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 1024 \\\n",
    "    --max_prompt_length 1000 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length normalization\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 2 \\\n",
    "    --learning_rate 1.0e-6 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_dpo_beta_0.01_normalized\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 1024 \\\n",
    "    --max_prompt_length 1000 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further length normalization and beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --learning_rate 1.0e-6 \\\n",
    "    --gradient_accumulation_steps 32 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_dpo_beta_10_normalized_sft_0.5\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 2048 \\\n",
    "    --max_prompt_length 1800 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home advantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home advantage with different values (2, dpo)\n",
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"<some path>/trl/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 2 \\\n",
    "    --learning_rate 1.0e-6 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_dpo_beta_10_normalized_hadv_-0.05\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 1024 \\\n",
    "    --max_prompt_length 1000 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rainbow-PO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RainbowPO retest\n",
    "!NCCL_P2P_DISABLE=1 accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3_opt_offload.yaml --num_processes 7 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"/home/hanyang/RainbowPO/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"meta-llama/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --learning_rate 1e-6 \\\n",
    "    --gradient_accumulation_steps 18 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --report_to wandb \\\n",
    "    --logging_steps 5 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"/home/hanyang/RainbowPO/models_rlhf/Llama3-Instruct_armorm_rainbowpo_beta_10_normalized_hadv_0.1_mixing_0.25\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 2048 \\\n",
    "    --max_prompt_length 1024 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RainbowPO on Llama-3-Instruct\n",
    "!NCCL_P2P_DISABLE=1 accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3_opt_offload.yaml --num_processes 7 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"/home/hanyang/RainbowPO/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"meta-llama/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --learning_rate 5e-7 \\\n",
    "    --gradient_accumulation_steps 36 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --report_to wandb \\\n",
    "    --logging_steps 5 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"/home/hanyang/RainbowPO/models_rlhf/Llama3-Instruct_armorm_rainbowpo_beta_1_hadv_0.1_mixing_0.25_square_hinge_loss\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 2048 \\\n",
    "    --max_prompt_length 1800 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2' \\\n",
    "    --beta 1 \\\n",
    "    --loss_type 'mallows_ipo_modified' \\\n",
    "    --if_mixing_alpha True \\\n",
    "    --mixing_alpha 0.25 \\\n",
    "    --length_normalization True \\\n",
    "    --home_advantage 0.1 \\\n",
    "    --num_train_epochs 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"/home/hanyang/RainbowPO/examples/datasets/UltraFeedback_armorm_trl\" \\\n",
    "    --model_name_or_path=\"meta-llama/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --learning_rate 5e-7 \\\n",
    "    --gradient_accumulation_steps 36 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --report_to wandb \\\n",
    "    --logging_steps 5 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"/home/hanyang/RainbowPO/models_rlhf/Llama3-Instruct_armorm_rainbowpo_beta_1_hadv_0.1_mixing_0.25_square_hinge_loss\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 2048 \\\n",
    "    --max_prompt_length 1024 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2' \\\n",
    "    --beta 1 \\\n",
    "    --loss_type 'mallows_ipo_modified' \\\n",
    "    --if_mixing_alpha True \\\n",
    "    --mixing_alpha 0.25 \\\n",
    "    --length_normalization True \\\n",
    "    --home_advantage 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPO with RSO\n",
    "!NCCL_P2P_DISABLE=1 accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3_opt_offload.yaml --num_processes 7 examples/scripts/dpo_zero3.py \\\n",
    "    --dataset_name=\"examples/datasets/UltraFeedback_armorm_rso_alpha=2.0_trl\" \\\n",
    "    --model_name_or_path=\"meta-llama/Meta-Llama-3-8B-Instruct\" \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --learning_rate 5e-7 \\\n",
    "    --gradient_accumulation_steps 18 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --logging_steps 5 \\\n",
    "    --save_steps 50000 \\\n",
    "    --output_dir=\"models_rlhf/Llama3-Instruct_armorm_rso_alpha_2.0_beta_0.05_lr_0.5_1epoch\" \\\n",
    "    --optim adamw_torch \\\n",
    "    --max_length 1024 \\\n",
    "    --max_prompt_length 1000 \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_steps 150 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2' \\\n",
    "    --num_train_epochs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "accelerate launch --config_file examples/accelerate_configs/deepspeed_zero3.yaml --num_processes 8 examples/scripts/online_dpo_zero3.py \\\n",
    "    --learning_rate 5e-7 \\\n",
    "    --output_dir \"<some path>/trl/models_rlhf/Llama3-Instruct_armorm_onlinedpo_beta_0.05\" \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --local_rollout_forward_batch_size 1 \\\n",
    "    --num_epochs 1 \\\n",
    "    --num_mini_batches 1 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --total_episodes 1000000 \\\n",
    "    --model_name_or_path \"<some path>/model_zoo/Meta-Llama-3-8B-Instruct\"  \\\n",
    "    --reward_model_path \"<some path>/Utilities/RLHFlow_ArmoRM-Llama3-8B-v0.1\" \\\n",
    "    --save_strategy no \\\n",
    "    --non_eos_penalty \\\n",
    "    --stop_token eos \\\n",
    "    --beta 0.05 \\\n",
    "    --response_length 2048 \\\n",
    "    --optim adamw_torch \\\n",
    "    --seed 42 \\\n",
    "    --bf16 \\\n",
    "    --warmup_ratio 0.1 \\\n",
    "    --logging_first_step \\\n",
    "    --no_remove_unused_columns \\\n",
    "    --attn_implementation 'flash_attention_2' \\\n",
    "    --sanity_check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
